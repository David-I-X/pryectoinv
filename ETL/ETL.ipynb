{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxLgHtfSYqTi"
      },
      "source": [
        "**Data Enigeering**\n",
        "\n",
        "[Repositorio](https://github.com/soyHenry/PI_ML_OPS/tree/PT?tab=readme-ov-file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcBwHkaQuOju"
      },
      "source": [
        "**Se define autoguardado en 60 segundos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FZQocakAuPM8",
        "outputId": "72f6f119-3127-484f-e723-168621e04bba"
      },
      "outputs": [],
      "source": [
        "autosave 60"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJY4K3WCMVoS"
      },
      "source": [
        "**Se importan las librerías necesarias para el proyecto**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OOob8b9bMQi-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-t0oZwpM5ut"
      },
      "outputs": [],
      "source": [
        "# Cargar el dataset\n",
        "df_movies = pd.read_csv('movies_dataset.csv')\n",
        "df_credits = pd.read_csv('credits.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminar columnas no utilizadas\n",
        "columns_to_drop = ['video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage']\n",
        "df_movies.drop(columns=columns_to_drop, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rellenar valores nulos de 'revenue' y 'budget' con 0\n",
        "df_movies['revenue'] = df_movies['revenue'].fillna(0)\n",
        "df_movies['budget'] = df_movies['budget'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Eliminar filas con valores nulos en 'release_date'\n",
        "df_movies = df_movies.dropna(subset=['release_date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asegurar que las fechas están en el formato AAAA-mm-dd\n",
        "df_movies['release_date'] = pd.to_datetime(df_movies['release_date'], errors='coerce')\n",
        "df_movies = df_movies.dropna(subset=['release_date'])  # Eliminar filas donde la conversión a datetime falla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear la columna 'release_year'\n",
        "df_movies['release_year'] = df_movies['release_date'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change column type to object for column: 'budget'\n",
        "df_movies = df_movies.astype({'budget': 'int'})\n",
        "\n",
        "# Crear la columna 'return'\n",
        "df_movies['return'] = df_movies.apply(lambda row: row['revenue'] / row['budget'] if row['budget'] > 0 else 0, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Desempaquetado de todas las columnas anidadas\n",
        "datos = []\n",
        "for indice, fila in df_movies.iterrows():\n",
        "    # Desanidar belongs_to_collection\n",
        "    collection_id = None\n",
        "    collection_name = None\n",
        "    if pd.notna(fila['belongs_to_collection']):\n",
        "        collection_data = ast.literal_eval(fila['belongs_to_collection'])\n",
        "        collection_id = collection_data['id']\n",
        "        collection_name = collection_data['name']\n",
        "    \n",
        "    # Desanidar genres\n",
        "    if pd.notna(fila['genres']):\n",
        "        genres_list = ast.literal_eval(fila['genres'])\n",
        "    else:\n",
        "        genres_list = []\n",
        "    \n",
        "    # Desanidar production_companies\n",
        "    if pd.notna(fila['production_companies']):\n",
        "        companies_list = ast.literal_eval(fila['production_companies'])\n",
        "    else:\n",
        "        companies_list = []\n",
        "    \n",
        "    # Desanidar spoken_languages\n",
        "    if pd.notna(fila['spoken_languages']):\n",
        "        languages_list = ast.literal_eval(fila['spoken_languages'])\n",
        "    else:\n",
        "        languages_list = []\n",
        "\n",
        "    # Desanidar production_countries\n",
        "    if pd.notna(fila['production_countries']):\n",
        "        countries_list = ast.literal_eval(fila['production_countries'])\n",
        "    else:\n",
        "        countries_list = []\n",
        "\n",
        "    # Crear combinaciones de todos los atributos\n",
        "    for genre in genres_list:\n",
        "        for company in companies_list:\n",
        "            for language in languages_list:\n",
        "                for country in countries_list:\n",
        "                    genre_id = genre['id']\n",
        "                    genre_name = genre['name']\n",
        "                    company_id = company['id']\n",
        "                    company_name = company['name']\n",
        "                    language_iso = language['iso_639_1']\n",
        "                    language_name = language['name']\n",
        "                    country_iso = country['iso_3166_1']\n",
        "                    country_name = country['name']\n",
        "                    datos.append({\n",
        "                        'collection_id': collection_id,\n",
        "                        'collection_name': collection_name,\n",
        "                        'genre_id': genre_id,\n",
        "                        'genre_name': genre_name,\n",
        "                        'company_id': company_id,\n",
        "                        'company_name': company_name,\n",
        "                        'language_iso': language_iso,\n",
        "                        'language_name': language_name,\n",
        "                        'country_iso': country_iso,\n",
        "                        'country_name': country_name,\n",
        "                        **fila.drop(['belongs_to_collection', 'genres', 'production_companies', 'spoken_languages', 'production_countries'])\n",
        "                    })\n",
        "\n",
        "df_movies = pd.DataFrame(datos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_movies['popularity'].fillna(0, inplace=True)\n",
        "df_movies['popularity'] = pd.to_numeric(df_movies['popularity'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_movies.to_parquet(\"movies.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_movies = pd.read_parquet('movies.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CREDITS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_credits.describe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Desempaquetado de las columnas 'cast' y 'crew'\n",
        "datos = []\n",
        "for indice, fila in df_credits.iterrows():\n",
        "    # Desanidar cast\n",
        "    if pd.notna(fila['cast']):\n",
        "        cast_list = ast.literal_eval(fila['cast'])\n",
        "    else:\n",
        "        cast_list = []\n",
        "    \n",
        "    # Desanidar crew\n",
        "    if pd.notna(fila['crew']):\n",
        "        crew_list = ast.literal_eval(fila['crew'])\n",
        "    else:\n",
        "        crew_list = []\n",
        "\n",
        "    # Añadir cada miembro del reparto\n",
        "    for cast_member in cast_list:\n",
        "        cast_id = cast_member['cast_id']\n",
        "        character = cast_member['character']\n",
        "        credit_id = cast_member['credit_id']\n",
        "        gender = cast_member['gender']\n",
        "        actor_id = cast_member['id']\n",
        "        name = cast_member['name']\n",
        "        order = cast_member['order']\n",
        "        profile_path = cast_member['profile_path']\n",
        "        datos.append({\n",
        "            'type': 'cast',\n",
        "            'cast_id': cast_id,\n",
        "            'character': character,\n",
        "            'credit_id': credit_id,\n",
        "            'gender': gender,\n",
        "            'actor_id': actor_id,\n",
        "            'name': name,\n",
        "            'order': order,\n",
        "            'profile_path': profile_path,\n",
        "            'movie_id': fila['id']\n",
        "        })\n",
        "    \n",
        "    # Añadir cada miembro del equipo\n",
        "    for crew_member in crew_list:\n",
        "        credit_id = crew_member['credit_id']\n",
        "        department = crew_member['department']\n",
        "        gender = crew_member['gender']\n",
        "        crew_id = crew_member['id']\n",
        "        job = crew_member['job']\n",
        "        name = crew_member['name']\n",
        "        profile_path = crew_member['profile_path']\n",
        "        datos.append({\n",
        "            'type': 'crew',\n",
        "            'credit_id': credit_id,\n",
        "            'department': department,\n",
        "            'gender': gender,\n",
        "            'crew_id': crew_id,\n",
        "            'job': job,\n",
        "            'name': name,\n",
        "            'profile_path': profile_path,\n",
        "            'movie_id': fila['id']\n",
        "        })\n",
        "\n",
        "df_desanidado = pd.DataFrame(datos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtrar solo directores\n",
        "directores = df_desanidado[(df_desanidado['type'] == 'crew') & (df_desanidado['job'] == 'Director')][['name', 'movie_id']].drop_duplicates()\n",
        "\n",
        "# Filtrar solo actores\n",
        "actores = df_desanidado[df_desanidado['type'] == 'cast'][['name', 'character', 'movie_id']]\n",
        "\n",
        "# Crear DataFrame final\n",
        "df_final = pd.merge(directores, actores, on='movie_id', suffixes=('_director', '_actor'))\n",
        "\n",
        "# Seleccionar las columnas requeridas\n",
        "df_credits = df_final[['name_director', 'name_actor', 'character']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_credits.to_parquet(\"creditsP.parquet\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_credits = pd.read_parquet('creditsP.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "se convertira el archivo original de 'credits.csv' a formato parquet para poder ser subido a git hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_credits = pd.read_csv('credits.csv')\n",
        "df_credits.to_parquet(\"credits.parquet\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
